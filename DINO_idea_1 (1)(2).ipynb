{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5aPRzkEntIE",
        "outputId": "cbd2f9a1-c837-4568-d89d-3101eb6d0774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-01-29 16:11:20--  https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain_full_checkpoint.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 352284107 (336M) [application/zip]\n",
            "Saving to: ‘dino_deitsmall8_pretrain_full_checkpoint.pth’\n",
            "\n",
            "dino_deitsmall8_pre 100%[===================>] 335.96M  6.73MB/s    in 50s     \n",
            "\n",
            "2023-01-29 16:12:11 (6.76 MB/s) - ‘dino_deitsmall8_pretrain_full_checkpoint.pth’ saved [352284107/352284107]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!wget https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain_full_checkpoint.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwDilcVAY3CJ",
        "outputId": "9cfc0332-623e-47d5-f07f-a90985a0c7bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sAr56K5yfd5H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "checkpoint = torch.load('/content/checkpoint.pth')\n",
        "checkpoint['epoch']=0\n",
        "torch.save(checkpoint,'/content/checkpoint.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_u1hOQNcMSe",
        "outputId": "fc5f3e6c-81e2-42d3-9fbc-bd059d1b05d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/xdg-open: 869: www-browser: not found\n",
            "/usr/bin/xdg-open: 869: links2: not found\n",
            "/usr/bin/xdg-open: 869: elinks: not found\n",
            "/usr/bin/xdg-open: 869: links: not found\n",
            "/usr/bin/xdg-open: 869: lynx: not found\n",
            "/usr/bin/xdg-open: 869: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=i6sdlswXpmF3Qmzy04Wb3yRb9SYgUWzrLJ4x7NJhA3A'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=i6sdlswXpmF3Qmzy04Wb3yRb9SYgUWzrLJ4x7NJhA3A\")\n",
            "/content\n",
            "/content/gdrive\n",
            "Access token retrieved correctly.\n"
          ]
        }
      ],
      "source": [
        "!sudo echo -ne '\\n' | sudo add-apt-repository ppa:alessandro-strada/ppa >/dev/null 2>&1 # note: >/dev/null 2>&1 is used to supress printing\n",
        "!sudo apt update >/dev/null 2>&1\n",
        "!sudo apt install google-drive-ocamlfuse >/dev/null 2>&1\n",
        "!google-drive-ocamlfuse\n",
        "!sudo apt-get install w3m >/dev/null 2>&1 # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop >/dev/null 2>&1 # to set default browser \n",
        "%cd /content\n",
        "!mkdir gdrive\n",
        "%cd gdrive\n",
        "!mkdir \"My Drive\"\n",
        "!google-drive-ocamlfuse \"/content/gdrive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRU1dRogcMQz",
        "outputId": "65feb04a-8fd7-48fa-84ee-fc93dead4aa7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "w3m is already the newest version (0.5.3-37ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "/content\n",
            "mkdir: cannot create directory ‘gdrive’: File exists\n",
            "/content/gdrive\n",
            "mkdir: cannot create directory ‘My Drive’: File exists\n",
            "fuse: mountpoint is not empty\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser \n",
        "%cd /content\n",
        "!mkdir gdrive\n",
        "%cd gdrive\n",
        "!mkdir \"My Drive\"\n",
        "!google-drive-ocamlfuse \"/content/gdrive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaQyecNKT3os",
        "outputId": "50107561-dc8f-4005-e83e-c9ca38c62171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "/content/drive/MyDrive/models/dino-main\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pwd \n",
        "%cd drive/MyDrive/models/dino-main/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRZnynU0VbbZ",
        "outputId": "e11161b2-d8ad-4829-d9ed-6bb97b895625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeJaaRfKcJ0l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# !os.mkdir('/content/datasst/supervisedS1')\n",
        "!mkdir '/content/supervisedS1'\n",
        "!mkdir '/content/supervisedS2'\n",
        "!mkdir '/content/supervisedS3'\n",
        "\n",
        "# !os.mkdir('/content/supervisedS2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLOBd_K9wmfK"
      },
      "outputs": [],
      "source": [
        "!mkdir '/content/supervisedS1/s1'\n",
        "!mkdir '/content/supervisedS2/s2'\n",
        "!mkdir '/content/supervisedS3/s3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtiRSFfHhHn5"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "import random\n",
        "import shutil\n",
        "files='/content/drive/MyDrive/datasets/CRC/train/s1/'\n",
        "files=os.listdir(files)\n",
        "random.seed(42)\n",
        "sample_files=sample(files,2000)\n",
        "for i in range(len(sample_files)):\n",
        "  shutil.copy2('/content/drive/MyDrive/datasets/CRC/train/s1/'+sample_files[i],'/content/supervisedS1/s1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNTV066Gw0Pn"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "import random\n",
        "import shutil\n",
        "files='/content/drive/MyDrive/datasets/CRC/train/s2/'\n",
        "files=os.listdir(files)\n",
        "random.seed(42)\n",
        "sample_files=sample(files,2000)\n",
        "for i in range(len(sample_files)):\n",
        "  shutil.copy2('/content/drive/MyDrive/datasets/CRC/train/s2/'+sample_files[i],'/content/supervisedS2/s2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDCcGf0rw3WS"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "import random\n",
        "import shutil\n",
        "files='/content/drive/MyDrive/datasets/CRC/train/s3/'\n",
        "files=os.listdir(files)\n",
        "random.seed(42)\n",
        "sample_files=sample(files,2000)\n",
        "for i in range(len(sample_files)):\n",
        "  shutil.copy2('/content/drive/MyDrive/datasets/CRC/train/s3/'+sample_files[i],'/content/supervisedS3/s3')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrlaeAwVtUA3",
        "outputId": "ffae4f49-f4cc-4043-8a96-9d1487e65461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Jan 25 20:53:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i1-wCfVxnw9",
        "outputId": "f44e8fb1-8a1d-4bdd-c774-3158d1c3e556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 29 12:50:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    29W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm==0.4.9 in /usr/local/lib/python3.8/dist-packages (0.4.9)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm==0.4.9) (0.14.1+cu116)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.8/dist-packages (from timm==0.4.9) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->timm==0.4.9) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (2.25.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (7.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.8/dist-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "!pip install timm==0.4.9\n",
        "!pip install yacs\n",
        "!pip install -U PyYAML\n",
        "!pip install einops\n",
        "# %cd /content\n",
        "%cd /content/drive/MyDrive/MICCAI/notebooks/dino-main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW6PhqfoUASx",
        "outputId": "4b116091-a156-4b9c-b6cf-30fdd4208086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1-4BFJrnMPRP0fn2KzLHYyceSdQ6nkCLI/dino-main\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/MICCAI/notebooks/dino-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "43iNPsFG1dmE",
        "outputId": "a8453a25-5621-4af3-a04b-ab30e1406c91"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b0b837b738ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import time\n",
        "while 1:\n",
        "  time.sleep(60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vodj90NBdJxo",
        "outputId": "b95b743f-3e3e-4099-a988-edeaa2528bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/models/dino-main\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "root_dir = \"/content/supervisedS1/\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "dataset_s1 = ImageFolder(\"/content/supervisedS1/\", transform=transform)\n",
        "dataloader_s1_1 = DataLoader(dataset_s1, batch_size=8, shuffle=True)\n",
        "dataloader_s1_2 = DataLoader(dataset_s1, batch_size=8, shuffle=True)\n",
        "\n",
        "dataset_s2 = ImageFolder(\"/content/supervisedS2/\", transform=transform)\n",
        "dataloader_s2_1 = DataLoader(dataset_s2, batch_size=8, shuffle=True)\n",
        "dataloader_s2_2 = DataLoader(dataset_s2, batch_size=8, shuffle=True)\n",
        "\n",
        "dataset_s3 = ImageFolder(\"/content/supervisedS3/\", transform=transform)\n",
        "dataloader_s3_1 = DataLoader(dataset_s3, batch_size=8, shuffle=True)\n",
        "dataloader_s3_2 = DataLoader(dataset_s3, batch_size=8, shuffle=True)\n",
        "\n",
        "%cd /content/drive/MyDrive/models/dino-main/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEbuPPcEgCgF",
        "outputId": "88472948-6c1b-424a-8065-87ccadd4f460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/models/dino-main\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/models/dino-main/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BZVDbtUwOpV",
        "outputId": "ca858c44-f1d3-466d-87fc-87d59d073499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 29 16:13:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.4.9\n",
            "  Downloading timm-0.4.9-py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.1/346.1 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.8/dist-packages (from timm==0.4.9) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm==0.4.9) (0.14.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.4->timm==0.4.9) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (2.25.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm==0.4.9) (1.21.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->timm==0.4.9) (1.24.3)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs) (6.0)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# %cd /content/drive/MyDrive/models/dino-main/\n",
        "\n",
        "!nvidia-smi\n",
        "!pip install timm==0.4.9\n",
        "!pip install yacs\n",
        "!pip install -U PyYAML\n",
        "!pip install einops\n",
        "# %cd /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi\n",
        "# !pip install timm==0.4.9\n",
        "# !pip install yacs\n",
        "# !pip install -U PyYAML\n",
        "# !pip install einops\n",
        "# %cd /content\n",
        "%cd /content/drive/MyDrive/MICCAI/notebooks/dino-main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHflTIC4luNz",
        "outputId": "9fc6ca71-8013-4bb8-f323-56ac7baa6de5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1-4BFJrnMPRP0fn2KzLHYyceSdQ6nkCLI/dino-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iJr14Ka1O0oL",
        "outputId": "55006238-32ca-4dcf-9dfa-f3908ed9b247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1-4BFJrnMPRP0fn2KzLHYyceSdQ6nkCLI/dino-main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/xcit/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will run the code on one GPU.\n",
            "| distributed init (rank 0): env://\n",
            "git:\n",
            "  sha: N/A, status: clean, branch: N/A\n",
            "\n",
            "arch: vit_small\n",
            "batch_size_per_gpu: 8\n",
            "clip_grad: 3.0\n",
            "data_path: /content/gdrive/My Drive/datasets/CRC/train/\n",
            "dist_url: env://\n",
            "drop_path_rate: 0.1\n",
            "epochs: 100\n",
            "freeze_last_layer: 1\n",
            "global_crops_scale: (0.4, 1.0)\n",
            "gpu: 0\n",
            "local_crops_number: 0\n",
            "local_crops_scale: (0.05, 0.4)\n",
            "local_rank: 0\n",
            "lr: 0.0005\n",
            "min_lr: 1e-06\n",
            "momentum_teacher: 0.996\n",
            "norm_last_layer: True\n",
            "num_workers: 10\n",
            "optimizer: adamw\n",
            "out_dim: 65536\n",
            "output_dir: .\n",
            "patch_size: 8\n",
            "rank: 0\n",
            "saveckp_freq: 20\n",
            "seed: 0\n",
            "teacher_temp: 0.04\n",
            "use_bn_in_head: False\n",
            "use_fp16: True\n",
            "warmup_epochs: 10\n",
            "warmup_teacher_temp: 0.04\n",
            "warmup_teacher_temp_epochs: 0\n",
            "weight_decay: 0.04\n",
            "weight_decay_end: 0.4\n",
            "world_size: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py:899: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded: there are 42885 images.\n",
            "Student and Teacher are built: they are both vit_small network.\n",
            "Loss, optimizer and schedulers ready.\n",
            "Found checkpoint at /content/checkpoint.pth\n",
            "=> loaded 'student' from checkpoint '/content/checkpoint.pth' with msg <All keys matched successfully>\n",
            "=> loaded 'teacher' from checkpoint '/content/checkpoint.pth' with msg <All keys matched successfully>\n",
            "=> key 'optimizer' not found in checkpoint: '/content/checkpoint.pth'\n",
            "=> key 'fp16_scaler' not found in checkpoint: '/content/checkpoint.pth'\n",
            "=> key 'dino_loss' not found in checkpoint: '/content/checkpoint.pth'\n",
            "Starting DINO training !\n",
            "Epoch: [0/100]  [   0/5360]  eta: 1 day, 3:56:30  loss: 6.594022 (6.594022)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 18.766905  data: 10.867044  max mem: 7206\n",
            "Epoch: [0/100]  [  10/5360]  eta: 4:02:33  loss: 7.290809 (7.098059)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 2.720232  data: 0.988356  max mem: 7502\n",
            "Epoch: [0/100]  [  20/5360]  eta: 2:55:39  loss: 7.559596 (7.387706)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.134119  data: 0.000442  max mem: 7503\n",
            "Epoch: [0/100]  [  30/5360]  eta: 2:31:44  loss: 7.865436 (7.717887)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.151435  data: 0.000675  max mem: 7503\n",
            "Epoch: [0/100]  [  40/5360]  eta: 2:19:21  loss: 8.785316 (8.021474)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.149595  data: 0.000659  max mem: 7503\n",
            "Epoch: [0/100]  [  50/5360]  eta: 2:12:13  loss: 8.684763 (8.114129)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.162512  data: 0.027218  max mem: 7503\n",
            "Epoch: [0/100]  [  60/5360]  eta: 2:11:02  loss: 8.686600 (8.330484)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.302335  data: 0.178220  max mem: 7503\n",
            "Epoch: [0/100]  [  70/5360]  eta: 2:15:42  loss: 9.250141 (8.469000)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.653935  data: 0.529993  max mem: 7503\n",
            "Epoch: [0/100]  [  80/5360]  eta: 2:15:42  loss: 9.112434 (8.529804)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.721342  data: 0.587913  max mem: 7503\n",
            "Epoch: [0/100]  [  90/5360]  eta: 2:15:19  loss: 8.957681 (8.597004)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.546561  data: 0.400765  max mem: 7503\n",
            "Epoch: [0/100]  [ 100/5360]  eta: 2:13:10  loss: 9.210489 (8.696835)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.425290  data: 0.277417  max mem: 7503\n",
            "Epoch: [0/100]  [ 110/5360]  eta: 2:13:33  loss: 9.674577 (8.795063)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.461204  data: 0.317693  max mem: 7503\n",
            "Epoch: [0/100]  [ 120/5360]  eta: 2:12:40  loss: 9.476678 (8.825230)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.519560  data: 0.385529  max mem: 7503\n",
            "Epoch: [0/100]  [ 130/5360]  eta: 2:11:28  loss: 8.728189 (8.816297)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.408097  data: 0.274440  max mem: 7503\n",
            "Epoch: [0/100]  [ 140/5360]  eta: 2:11:25  loss: 9.322721 (8.867570)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.459290  data: 0.331340  max mem: 7503\n",
            "Epoch: [0/100]  [ 150/5360]  eta: 2:10:54  loss: 9.521447 (8.909722)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.501789  data: 0.379226  max mem: 7503\n",
            "Epoch: [0/100]  [ 160/5360]  eta: 2:11:41  loss: 9.690067 (8.964605)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.581661  data: 0.451177  max mem: 7503\n",
            "Epoch: [0/100]  [ 170/5360]  eta: 2:10:46  loss: 9.763483 (8.998138)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.543943  data: 0.409727  max mem: 7503\n",
            "Epoch: [0/100]  [ 180/5360]  eta: 2:10:45  loss: 9.434539 (9.010539)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.475711  data: 0.338876  max mem: 7503\n",
            "Epoch: [0/100]  [ 190/5360]  eta: 2:10:19  loss: 9.378138 (9.019298)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.517905  data: 0.381507  max mem: 7503\n",
            "Epoch: [0/100]  [ 200/5360]  eta: 2:09:02  loss: 9.253141 (9.039455)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.372887  data: 0.246805  max mem: 7503\n",
            "Epoch: [0/100]  [ 210/5360]  eta: 2:07:16  loss: 9.274521 (9.054246)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.199840  data: 0.077009  max mem: 7503\n",
            "Epoch: [0/100]  [ 220/5360]  eta: 2:05:39  loss: 9.587759 (9.097112)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.127877  data: 0.000833  max mem: 7503\n",
            "Epoch: [0/100]  [ 230/5360]  eta: 2:04:11  loss: 9.470737 (9.100943)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.132593  data: 0.000999  max mem: 7503\n",
            "Epoch: [0/100]  [ 240/5360]  eta: 2:02:47  loss: 9.385647 (9.108027)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.131609  data: 0.001164  max mem: 7503\n",
            "Epoch: [0/100]  [ 250/5360]  eta: 2:01:31  loss: 9.445070 (9.114099)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.131454  data: 0.004213  max mem: 7503\n",
            "Epoch: [0/100]  [ 260/5360]  eta: 2:00:55  loss: 9.498897 (9.122872)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.227013  data: 0.100008  max mem: 7503\n",
            "Epoch: [0/100]  [ 270/5360]  eta: 2:00:35  loss: 9.424379 (9.137449)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.354860  data: 0.225214  max mem: 7503\n",
            "Epoch: [0/100]  [ 280/5360]  eta: 2:00:34  loss: 9.424379 (9.148999)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.442909  data: 0.310182  max mem: 7503\n",
            "Epoch: [0/100]  [ 290/5360]  eta: 2:01:27  loss: 9.424171 (9.149953)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.650916  data: 0.523969  max mem: 7503\n",
            "Epoch: [0/100]  [ 300/5360]  eta: 2:01:20  loss: 9.424171 (9.151684)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.643928  data: 0.497491  max mem: 7503\n",
            "Epoch: [0/100]  [ 310/5360]  eta: 2:01:20  loss: 9.549784 (9.157077)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.505945  data: 0.344179  max mem: 7503\n",
            "Epoch: [0/100]  [ 320/5360]  eta: 2:01:24  loss: 9.684566 (9.174148)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.545268  data: 0.405794  max mem: 7503\n",
            "Epoch: [0/100]  [ 330/5360]  eta: 2:02:04  loss: 9.101690 (9.165193)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.679556  data: 0.552981  max mem: 7503\n",
            "Epoch: [0/100]  [ 340/5360]  eta: 2:01:32  loss: 8.860979 (9.160919)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.568481  data: 0.443162  max mem: 7503\n",
            "Epoch: [0/100]  [ 350/5360]  eta: 2:01:33  loss: 8.966200 (9.166637)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.449203  data: 0.312046  max mem: 7503\n",
            "Epoch: [0/100]  [ 360/5360]  eta: 2:01:16  loss: 9.238323 (9.169830)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.500598  data: 0.365207  max mem: 7503\n",
            "Epoch: [0/100]  [ 370/5360]  eta: 2:02:09  loss: 9.238323 (9.167866)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.699243  data: 0.570942  max mem: 7503\n",
            "Epoch: [0/100]  [ 380/5360]  eta: 2:02:00  loss: 8.875466 (9.161946)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.735064  data: 0.602585  max mem: 7503\n",
            "Epoch: [0/100]  [ 390/5360]  eta: 2:02:06  loss: 8.875466 (9.153050)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.573348  data: 0.439015  max mem: 7503\n",
            "Epoch: [0/100]  [ 400/5360]  eta: 2:01:40  loss: 8.953240 (9.148490)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.509012  data: 0.367664  max mem: 7503\n",
            "Epoch: [0/100]  [ 410/5360]  eta: 2:02:10  loss: 9.047723 (9.145703)  lr: 0.000000 (0.000000)  wd: 0.040000 (0.040000)  time: 1.613497  data: 0.480469  max mem: 7503\n",
            "Epoch: [0/100]  [ 420/5360]  eta: 2:02:07  loss: 8.981756 (9.140883)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.712543  data: 0.587177  max mem: 7503\n",
            "Epoch: [0/100]  [ 430/5360]  eta: 2:02:14  loss: 9.161817 (9.144018)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.628637  data: 0.500401  max mem: 7503\n",
            "Epoch: [0/100]  [ 440/5360]  eta: 2:02:55  loss: 9.177980 (9.143012)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.830775  data: 0.700117  max mem: 7503\n",
            "Epoch: [0/100]  [ 450/5360]  eta: 2:02:35  loss: 9.055099 (9.138733)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.718280  data: 0.593046  max mem: 7503\n",
            "Epoch: [0/100]  [ 460/5360]  eta: 2:02:29  loss: 9.032484 (9.135521)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.517632  data: 0.386945  max mem: 7503\n",
            "Epoch: [0/100]  [ 470/5360]  eta: 2:02:32  loss: 8.591072 (9.127357)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.628268  data: 0.491241  max mem: 7503\n",
            "Epoch: [0/100]  [ 480/5360]  eta: 2:02:49  loss: 8.591072 (9.120459)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.747978  data: 0.615451  max mem: 7503\n",
            "Epoch: [0/100]  [ 490/5360]  eta: 2:02:24  loss: 8.596160 (9.112479)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.616459  data: 0.485074  max mem: 7503\n",
            "Epoch: [0/100]  [ 500/5360]  eta: 2:02:05  loss: 8.908379 (9.105751)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.438811  data: 0.309265  max mem: 7503\n",
            "Epoch: [0/100]  [ 510/5360]  eta: 2:01:59  loss: 9.107272 (9.104956)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.531480  data: 0.393469  max mem: 7503\n",
            "Epoch: [0/100]  [ 520/5360]  eta: 2:01:10  loss: 8.776842 (9.092675)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.373145  data: 0.240970  max mem: 7503\n",
            "Epoch: [0/100]  [ 530/5360]  eta: 2:00:22  loss: 8.776842 (9.092806)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.143326  data: 0.017025  max mem: 7503\n",
            "Epoch: [0/100]  [ 540/5360]  eta: 1:59:33  loss: 8.938551 (9.093477)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.125128  data: 0.000493  max mem: 7503\n",
            "Epoch: [0/100]  [ 550/5360]  eta: 1:58:44  loss: 9.113209 (9.090606)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.109015  data: 0.000241  max mem: 7503\n",
            "Epoch: [0/100]  [ 560/5360]  eta: 1:58:00  loss: 8.741956 (9.077208)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.121295  data: 0.000640  max mem: 7503\n",
            "Epoch: [0/100]  [ 570/5360]  eta: 1:57:31  loss: 8.259675 (9.069861)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.217459  data: 0.093029  max mem: 7503\n",
            "Epoch: [0/100]  [ 580/5360]  eta: 1:57:21  loss: 8.692572 (9.062731)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.417180  data: 0.301973  max mem: 7503\n",
            "Epoch: [0/100]  [ 590/5360]  eta: 1:57:23  loss: 8.692572 (9.055960)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.605130  data: 0.484618  max mem: 7503\n",
            "Epoch: [0/100]  [ 600/5360]  eta: 1:57:37  loss: 8.743410 (9.051859)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.756505  data: 0.625278  max mem: 7503\n",
            "Epoch: [0/100]  [ 610/5360]  eta: 1:57:04  loss: 9.023456 (9.057146)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.549804  data: 0.408580  max mem: 7503\n",
            "Epoch: [0/100]  [ 620/5360]  eta: 1:56:22  loss: 9.029510 (9.057296)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.189336  data: 0.058622  max mem: 7503\n",
            "Epoch: [0/100]  [ 630/5360]  eta: 1:55:41  loss: 9.102146 (9.059402)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.119634  data: 0.000291  max mem: 7503\n",
            "Epoch: [0/100]  [ 640/5360]  eta: 1:55:00  loss: 8.914890 (9.053756)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.114968  data: 0.000296  max mem: 7503\n",
            "Epoch: [0/100]  [ 650/5360]  eta: 1:54:20  loss: 8.914890 (9.050929)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.112145  data: 0.000287  max mem: 7503\n",
            "Epoch: [0/100]  [ 660/5360]  eta: 1:54:19  loss: 9.065449 (9.048278)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.379063  data: 0.260798  max mem: 7503\n",
            "Epoch: [0/100]  [ 670/5360]  eta: 1:54:20  loss: 8.944695 (9.039916)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.662577  data: 0.528750  max mem: 7503\n",
            "Epoch: [0/100]  [ 680/5360]  eta: 1:54:12  loss: 8.680842 (9.034177)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.616757  data: 0.474131  max mem: 7503\n",
            "Epoch: [0/100]  [ 690/5360]  eta: 1:54:54  loss: 8.680842 (9.032304)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040000)  time: 1.931870  data: 0.800880  max mem: 7503\n",
            "Epoch: [0/100]  [ 700/5360]  eta: 1:54:38  loss: 8.697184 (9.029215)  lr: 0.000000 (0.000000)  wd: 0.040001 (0.040001)  time: 1.881691  data: 0.747279  max mem: 7503\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-86a0caa5baea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m     \u001b[0mtrain_dino\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-86a0caa5baea>\u001b[0m in \u001b[0;36mtrain_dino\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# print('end s3',time.time()-s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         train_stats = train_one_epoch(student, teacher, teacher_without_ddp, dino_loss,\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd_schedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum_schedule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             epoch, fp16_scaler, args)\n",
            "\u001b[0;32m<ipython-input-10-86a0caa5baea>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(student, teacher, teacher_without_ddp, dino_loss, data_loader, optimizer, lr_schedule, wd_schedule, momentum_schedule, epoch, fp16_scaler, args)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mmetric_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetricLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"  \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epoch: [{}/{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;31m# update weight decay and learning rate according to their schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mit\u001b[0m  \u001b[0;31m# global training iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/.shortcut-targets-by-id/1-4BFJrnMPRP0fn2KzLHYyceSdQ6nkCLI/dino-main/utils.py\u001b[0m in \u001b[0;36mlog_every\u001b[0;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[1;32m    375\u001b[0m             ])\n\u001b[1;32m    376\u001b[0m         \u001b[0mMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\", line 229, in __getitem__\n    sample = self.loader(path)\n  File \"/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\", line 268, in default_loader\n    return pil_loader(path)\n  File \"/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\", line 248, in pil_loader\n    return img.convert(\"RGB\")\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/Image.py\", line 901, in convert\n    self.load()\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 270, in load\n    raise_ioerror(err_code)\n  File \"/usr/local/lib/python3.8/dist-packages/PIL/ImageFile.py\", line 59, in raise_ioerror\n    raise OSError(message + \" when reading image file\")\nOSError: unrecognized data stream contents when reading image file\n"
          ]
        }
      ],
      "source": [
        "# Copyright (c) Facebook, Inc. and its affiliates.\n",
        "# \n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "# \n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# \n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "%cd /content/drive/MyDrive/MICCAI/notebooks/dino-main\n",
        "import time\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "import datetime\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "from pathlib import Path\n",
        "from dataset import SingleData\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.distributed as dist\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision import models as torchvision_models\n",
        "import random\n",
        "import utils\n",
        "import vision_transformer as vits\n",
        "from vision_transformer import DINOHead\n",
        "\n",
        "torchvision_archs = sorted(name for name in torchvision_models.__dict__\n",
        "    if name.islower() and not name.startswith(\"__\")\n",
        "    and callable(torchvision_models.__dict__[name]))\n",
        "\n",
        "def get_args_parser():\n",
        "    parser = argparse.ArgumentParser('DINO', add_help=False)\n",
        "\n",
        "    # Model parameters\n",
        "    parser.add_argument('--arch', default='vit_small', type=str,\n",
        "        choices=['vit_tiny', 'vit_small', 'vit_base', 'xcit', 'deit_tiny', 'deit_small'] \\\n",
        "                + torchvision_archs + torch.hub.list(\"facebookresearch/xcit:main\"),\n",
        "        help=\"\"\"Name of architecture to train. For quick experiments with ViTs,\n",
        "        we recommend using vit_tiny or vit_small.\"\"\")\n",
        "    parser.add_argument('--patch_size', default=8, type=int, help=\"\"\"Size in pixels\n",
        "        of input square patches - default 16 (for 16x16 patches). Using smaller\n",
        "        values leads to better performance but requires more memory. Applies only\n",
        "        for ViTs (vit_tiny, vit_small and vit_base). If <16, we recommend disabling\n",
        "        mixed precision training (--use_fp16 false) to avoid unstabilities.\"\"\")\n",
        "    parser.add_argument('--out_dim', default=65536, type=int, help=\"\"\"Dimensionality of\n",
        "        the DINO head output. For complex and large datasets large values (like 65k) work well.\"\"\")\n",
        "    parser.add_argument('--norm_last_layer', default=True, type=utils.bool_flag,\n",
        "        help=\"\"\"Whether or not to weight normalize the last layer of the DINO head.\n",
        "        Not normalizing leads to better performance but can make the training unstable.\n",
        "        In our experiments, we typically set this paramater to False with vit_small and True with vit_base.\"\"\")\n",
        "    parser.add_argument('--momentum_teacher', default=0.996, type=float, help=\"\"\"Base EMA\n",
        "        parameter for teacher update. The value is increased to 1 during training with cosine schedule.\n",
        "        We recommend setting a higher value with small batches: for example use 0.9995 with batch size of 256.\"\"\")\n",
        "    parser.add_argument('--use_bn_in_head', default=False, type=utils.bool_flag,\n",
        "        help=\"Whether to use batch normalizations in projection head (Default: False)\")\n",
        "\n",
        "    # Temperature teacher parameters\n",
        "    parser.add_argument('--warmup_teacher_temp', default=0.04, type=float,\n",
        "        help=\"\"\"Initial value for the teacher temperature: 0.04 works well in most cases.\n",
        "        Try decreasing it if the training loss does not decrease.\"\"\")\n",
        "    parser.add_argument('--teacher_temp', default=0.04, type=float, help=\"\"\"Final value (after linear warmup)\n",
        "        of the teacher temperature. For most experiments, anything above 0.07 is unstable. We recommend\n",
        "        starting with the default value of 0.04 and increase this slightly if needed.\"\"\")\n",
        "    parser.add_argument('--warmup_teacher_temp_epochs', default=0, type=int,\n",
        "        help='Number of warmup epochs for the teacher temperature (Default: 30).')\n",
        "\n",
        "    # Training/Optimization parameters\n",
        "    parser.add_argument('--use_fp16', type=utils.bool_flag, default=True, help=\"\"\"Whether or not\n",
        "        to use half precision for training. Improves training time and memory requirements,\n",
        "        but can provoke instability and slight decay of performance. We recommend disabling\n",
        "        mixed precision if the loss is unstable, if reducing the patch size or if training with bigger ViTs.\"\"\")\n",
        "    parser.add_argument('--weight_decay', type=float, default=0.04, help=\"\"\"Initial value of the\n",
        "        weight decay. With ViT, a smaller value at the beginning of training works well.\"\"\")\n",
        "    parser.add_argument('--weight_decay_end', type=float, default=0.4, help=\"\"\"Final value of the\n",
        "        weight decay. We use a cosine schedule for WD and using a larger decay by\n",
        "        the end of training improves performance for ViTs.\"\"\")\n",
        "    parser.add_argument('--clip_grad', type=float, default=3.0, help=\"\"\"Maximal parameter\n",
        "        gradient norm if using gradient clipping. Clipping with norm .3 ~ 1.0 can\n",
        "        help optimization for larger ViT architectures. 0 for disabling.\"\"\")\n",
        "    parser.add_argument('--batch_size_per_gpu', default=8, type=int,\n",
        "        help='Per-GPU batch-size : number of distinct images loaded on one GPU.')\n",
        "    parser.add_argument('--epochs', default=100, type=int, help='Number of epochs of training.')\n",
        "    parser.add_argument('--freeze_last_layer', default=1, type=int, help=\"\"\"Number of epochs\n",
        "        during which we keep the output layer fixed. Typically doing so during\n",
        "        the first epoch helps training. Try increasing this value if the loss does not decrease.\"\"\")\n",
        "    parser.add_argument(\"--lr\", default=0.0005, type=float, help=\"\"\"Learning rate at the end of\n",
        "        linear warmup (highest LR used during training). The learning rate is linearly scaled\n",
        "        with the batch size, and specified here for a reference batch size of 256.\"\"\")\n",
        "    parser.add_argument(\"--warmup_epochs\", default=10, type=int,\n",
        "        help=\"Number of epochs for the linear learning-rate warm up.\")\n",
        "    parser.add_argument('--min_lr', type=float, default=1e-6, help=\"\"\"Target LR at the\n",
        "        end of optimization. We use a cosine LR schedule with linear warmup.\"\"\")\n",
        "    parser.add_argument('--optimizer', default='adamw', type=str,\n",
        "        choices=['adamw', 'sgd', 'lars'], help=\"\"\"Type of optimizer. We recommend using adamw with ViTs.\"\"\")\n",
        "    parser.add_argument('--drop_path_rate', type=float, default=0.1, help=\"stochastic depth rate\")\n",
        "\n",
        "    # Multi-crop parameters\n",
        "    parser.add_argument('--global_crops_scale', type=float, nargs='+', default=(0.4, 1.),\n",
        "        help=\"\"\"Scale range of the cropped image before resizing, relatively to the origin image.\n",
        "        Used for large global view cropping. When disabling multi-crop (--local_crops_number 0), we\n",
        "        recommand using a wider range of scale (\"--global_crops_scale 0.14 1.\" for example)\"\"\")\n",
        "    parser.add_argument('--local_crops_number', type=int, default=0, help=\"\"\"Number of small\n",
        "        local views to generate. Set this parameter to 0 to disable multi-crop training.\n",
        "        When disabling multi-crop we recommend to use \"--global_crops_scale 0.14 1.\" \"\"\")\n",
        "    parser.add_argument('--local_crops_scale', type=float, nargs='+', default=(0.05, 0.4),\n",
        "        help=\"\"\"Scale range of the cropped image before resizing, relatively to the origin image.\n",
        "        Used for small local view cropping of multi-crop.\"\"\")\n",
        "\n",
        "    # Misc\n",
        "    parser.add_argument('--data_path', default='/content/gdrive/My Drive/datasets/CRC/train/', type=str,\n",
        "        help='Please specify path to the ImageNet training data.')\n",
        "    parser.add_argument('--output_dir', default=\".\", type=str, help='Path to save logs and checkpoints.')\n",
        "    parser.add_argument('--saveckp_freq', default=20, type=int, help='Save checkpoint every x epochs.')\n",
        "    parser.add_argument('--seed', default=0, type=int, help='Random seed.')\n",
        "    parser.add_argument('--num_workers', default=10, type=int, help='Number of data loading workers per GPU.')\n",
        "    parser.add_argument(\"--dist_url\", default=\"env://\", type=str, help=\"\"\"url used to set up\n",
        "        distributed training; see https://pytorch.org/docs/stable/distributed.html\"\"\")\n",
        "    parser.add_argument(\"--local_rank\", default=0, type=int, help=\"Please ignore and do not set this argument.\")\n",
        "    return parser\n",
        "\n",
        "\n",
        "def train_dino(args):\n",
        "    utils.init_distributed_mode(args) \n",
        "    utils.fix_random_seeds(args.seed)\n",
        "    print(\"git:\\n  {}\\n\".format(utils.get_sha()))\n",
        "    print(\"\\n\".join(\"%s: %s\" % (k, str(v)) for k, v in sorted(dict(vars(args)).items())))\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # ============ preparing data ... ============\n",
        "    transform = DataAugmentationDINO(\n",
        "        args.global_crops_scale,\n",
        "        args.local_crops_scale,\n",
        "        args.local_crops_number,\n",
        "    )\n",
        "    # dataset_s1 = ImageFolder(\"/content/supervisedS1/\", transform=transform)\n",
        "    # sampler1 = torch.utils.data.DistributedSampler(dataset_s1, shuffle=True)\n",
        "    # dataloader_s1_1 = DataLoader(dataset_s1, batch_size=8,sampler=sampler1)\n",
        "    # dataloader_s1_2 = DataLoader(dataset_s1, batch_size=8,sampler=sampler1)\n",
        "\n",
        "    # dataset_s2 = ImageFolder(\"/content/supervisedS2/\", transform=transform)\n",
        "    # sampler2 = torch.utils.data.DistributedSampler(dataset_s2, shuffle=True)\n",
        "    # dataloader_s2_1 = DataLoader(dataset_s2, batch_size=8,sampler=sampler2)\n",
        "    # dataloader_s2_2 = DataLoader(dataset_s2, batch_size=8,sampler=sampler2)\n",
        "\n",
        "    # dataset_s3 = ImageFolder(\"/content/supervisedS3/\", transform=transform)\n",
        "    # sampler3 = torch.utils.data.DistributedSampler(dataset_s3, shuffle=True)\n",
        "    # dataloader_s3_1 = DataLoader(dataset_s3,sampler=sampler3, batch_size=8)\n",
        "    # dataloader_s3_2 = DataLoader(dataset_s3,sampler=sampler3, batch_size=8)\n",
        "\n",
        "    dataset = datasets.ImageFolder(args.data_path, transform=transform)\n",
        "    # class_name, train_img_list = get_data_list2('/content/drive/MyDrive/dataSets/CRC/train/',0.0)\n",
        "    # class_name, train_img_list = get_data_list('D:\\\\original_images_5\\\\test-patches\\\\trainset\\\\SPQ\\\\final\\\\train\\\\final\\\\final',0.0)\n",
        "    # dataset=SingleData(class_name, train_img_list, transform=transforms.ToTensor())\n",
        "    sampler = torch.utils.data.DistributedSampler(dataset, shuffle=True)\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        sampler=sampler,\n",
        "        batch_size=args.batch_size_per_gpu,\n",
        "        num_workers=args.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    print(f\"Data loaded: there are {len(dataset)} images.\")\n",
        "\n",
        "    # ============ building student and teacher networks ... ============\n",
        "    # we changed the name DeiT-S for ViT-S to avoid confusions\n",
        "    args.arch = args.arch.replace(\"deit\", \"vit\")\n",
        "    # if the network is a Vision Transformer (i.e. vit_tiny, vit_small, vit_base)\n",
        "    if args.arch in vits.__dict__.keys():\n",
        "        student = vits.__dict__[args.arch](\n",
        "            patch_size=args.patch_size,\n",
        "            drop_path_rate=args.drop_path_rate,  # stochastic depth\n",
        "        )\n",
        "        teacher = vits.__dict__[args.arch](patch_size=args.patch_size)\n",
        "        embed_dim = student.embed_dim\n",
        "    # if the network is a XCiT\n",
        "    elif args.arch in torch.hub.list(\"facebookresearch/xcit:main\"):\n",
        "        student = torch.hub.load('facebookresearch/xcit:main', args.arch,\n",
        "                                 pretrained=False, drop_path_rate=args.drop_path_rate)\n",
        "        teacher = torch.hub.load('facebookresearch/xcit:main', args.arch, pretrained=False)\n",
        "        embed_dim = student.embed_dim\n",
        "    # otherwise, we check if the architecture is in torchvision models\n",
        "    elif args.arch in torchvision_models.__dict__.keys():\n",
        "        student = torchvision_models.__dict__[args.arch]()\n",
        "        teacher = torchvision_models.__dict__[args.arch]()\n",
        "        embed_dim = student.fc.weight.shape[1]\n",
        "    else:\n",
        "        print(f\"Unknow architecture: {args.arch}\")\n",
        "\n",
        "    # multi-crop wrapper handles forward with inputs of different resolutions\n",
        "    student = utils.MultiCropWrapper(student, DINOHead(\n",
        "        embed_dim,\n",
        "        args.out_dim,\n",
        "        use_bn=args.use_bn_in_head,\n",
        "        norm_last_layer=args.norm_last_layer,\n",
        "    ))\n",
        "    teacher = utils.MultiCropWrapper(\n",
        "        teacher,\n",
        "        DINOHead(embed_dim, args.out_dim, args.use_bn_in_head),\n",
        "    )\n",
        "    # move networks to gpu\n",
        "    student, teacher = student.cuda(), teacher.cuda()\n",
        "    # synchronize batch norms (if any)\n",
        "    if utils.has_batchnorms(student):\n",
        "        student = nn.SyncBatchNorm.convert_sync_batchnorm(student)\n",
        "        teacher = nn.SyncBatchNorm.convert_sync_batchnorm(teacher)\n",
        "\n",
        "        # we need DDP wrapper to have synchro batch norms working...\n",
        "        teacher = nn.parallel.DistributedDataParallel(teacher, device_ids=[args.gpu])\n",
        "        teacher_without_ddp = teacher.module\n",
        "    else:\n",
        "        # teacher_without_ddp and teacher are the same thing\n",
        "        teacher_without_ddp = teacher\n",
        "    student = nn.parallel.DistributedDataParallel(student, device_ids=[args.gpu])\n",
        "    # teacher and student start with the same weights\n",
        "    teacher_without_ddp.load_state_dict(student.module.state_dict())\n",
        "    # there is no backpropagation through the teacher, so no need for gradients\n",
        "    for p in teacher.parameters():\n",
        "        p.requires_grad = False\n",
        "    print(f\"Student and Teacher are built: they are both {args.arch} network.\")\n",
        "\n",
        "    # ============ preparing loss ... ============\n",
        "    dino_loss = DINOLoss(\n",
        "        args.out_dim,\n",
        "        args.local_crops_number + 2,  # total number of crops = 2 global crops + local_crops_number\n",
        "        args.warmup_teacher_temp,\n",
        "        args.teacher_temp,\n",
        "        args.warmup_teacher_temp_epochs,\n",
        "        args.epochs,\n",
        "    ).cuda()\n",
        "\n",
        "    # ============ preparing optimizer ... ============\n",
        "    params_groups = utils.get_params_groups(student)\n",
        "    if args.optimizer == \"adamw\":\n",
        "        optimizer = torch.optim.AdamW(params_groups)  # to use with ViTs\n",
        "    elif args.optimizer == \"sgd\":\n",
        "        optimizer = torch.optim.SGD(params_groups, lr=0, momentum=0.9)  # lr is set by scheduler\n",
        "    elif args.optimizer == \"lars\":\n",
        "        optimizer = utils.LARS(params_groups)  # to use with convnet and large batches\n",
        "    # for mixed precision training\n",
        "    fp16_scaler = None\n",
        "    if args.use_fp16:\n",
        "        fp16_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # ============ init schedulers ... ============\n",
        "    lr_schedule = utils.cosine_scheduler(\n",
        "        args.lr * (args.batch_size_per_gpu * utils.get_world_size()) / 256.,  # linear scaling rule\n",
        "        args.min_lr,\n",
        "        args.epochs, len(data_loader),\n",
        "        warmup_epochs=args.warmup_epochs,\n",
        "    )\n",
        "    wd_schedule = utils.cosine_scheduler(\n",
        "        args.weight_decay,\n",
        "        args.weight_decay_end,\n",
        "        args.epochs, len(data_loader),\n",
        "    )\n",
        "\n",
        "    # lr_schedule_sup = utils.cosine_scheduler(\n",
        "    #     args.lr * (args.batch_size_per_gpu * utils.get_world_size()) / 256.,  # linear scaling rule\n",
        "    #     args.min_lr,\n",
        "    #     args.epochs, len(dataloader_s1_1),\n",
        "    #     warmup_epochs=args.warmup_epochs,\n",
        "    # )\n",
        "    # wd_schedule_sup = utils.cosine_scheduler(\n",
        "    #     args.weight_decay,\n",
        "    #     args.weight_decay_end,\n",
        "    #     args.epochs, len(dataloader_s1_1),\n",
        "    # )\n",
        "    # momentum parameter is increased to 1. during training with a cosine schedule\n",
        "    momentum_schedule = utils.cosine_scheduler(args.momentum_teacher, 1,\n",
        "                                               args.epochs, len(data_loader))\n",
        "    \n",
        "    # momentum_schedule_sup = utils.cosine_scheduler(args.momentum_teacher, 1,\n",
        "    #                                            args.epochs, len(dataloader_s1_1))\n",
        "    print(f\"Loss, optimizer and schedulers ready.\")\n",
        "\n",
        "    # ============ optionally resume training ... ============\n",
        "    to_restore = {\"epoch\": 0}\n",
        "    utils.restart_from_checkpoint(\n",
        "        os.path.join(args.output_dir, \"/content/checkpoint.pth\"),\n",
        "        run_variables=to_restore,\n",
        "        student=student,\n",
        "        teacher=teacher,\n",
        "        optimizer=optimizer,\n",
        "        fp16_scaler=fp16_scaler,\n",
        "        dino_loss=dino_loss,\n",
        "    )\n",
        "    start_epoch = to_restore[\"epoch\"]\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(\"Starting DINO training !\")\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        data_loader.sampler.set_epoch(epoch)\n",
        "        # dataloader_s1_1.sampler.set_epoch(epoch)\n",
        "        # dataloader_s2_1.sampler.set_epoch(epoch)\n",
        "        # dataloader_s3_1.sampler.set_epoch(epoch)\n",
        "\n",
        "\n",
        "\n",
        "        # ============ training one epoch of DINO ... ============\n",
        "        # print('start s1')\n",
        "        # s=time.time()\n",
        "   \n",
        "        # train_stats = train_one_epoch_supervised(student, teacher, teacher_without_ddp, dino_loss,\n",
        "        #     dataloader_s1_1,dataloader_s1_2, optimizer, lr_schedule_sup, wd_schedule_sup, momentum_schedule_sup,\n",
        "        #     epoch, fp16_scaler, args)\n",
        "        # print('end s1',time.time()-s)\n",
        "        # print('start s2')\n",
        "        # s=time.time()\n",
        "        \n",
        "        # train_stats = train_one_epoch_supervised(student, teacher, teacher_without_ddp, dino_loss,\n",
        "        #     dataloader_s2_1,dataloader_s2_2, optimizer, lr_schedule_sup, wd_schedule_sup, momentum_schedule_sup,\n",
        "        #     epoch, fp16_scaler, args)\n",
        "        \n",
        "        # print('end s2',time.time()-s)\n",
        "        # print('start s3')\n",
        "        # s=time.time()\n",
        "        # train_stats = train_one_epoch_supervised(student, teacher, teacher_without_ddp, dino_loss,\n",
        "        #     dataloader_s3_1,dataloader_s3_2, optimizer, lr_schedule_sup, wd_schedule_sup, momentum_schedule_sup,\n",
        "        #     epoch, fp16_scaler, args)\n",
        "        # print('end s3',time.time()-s)\n",
        "\n",
        "        train_stats = train_one_epoch(student, teacher, teacher_without_ddp, dino_loss,\n",
        "            data_loader, optimizer, lr_schedule, wd_schedule, momentum_schedule,\n",
        "            epoch, fp16_scaler, args)\n",
        "\n",
        "        # ============ writing logs ... ============\n",
        "        save_dict = {\n",
        "            'student': student.state_dict(),\n",
        "            'teacher': teacher.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': epoch + 1,\n",
        "            'args': args,\n",
        "            'dino_loss': dino_loss.state_dict(),\n",
        "        }\n",
        "        if fp16_scaler is not None:\n",
        "            save_dict['fp16_scaler'] = fp16_scaler.state_dict()\n",
        "        utils.save_on_master(save_dict, os.path.join(args.output_dir, '/content/drive/MyDrive/pretrained_models/DINO_IDEA_1/checkpoint.pth'))\n",
        "        if args.saveckp_freq and epoch % args.saveckp_freq == 0:\n",
        "            utils.save_on_master(save_dict, os.path.join(args.output_dir, f'/content/drive/MyDrive/pretrained_models/DINO_IDEA_1/checkpoint{epoch:04}.pth'))\n",
        "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
        "                     'epoch': epoch}\n",
        "        if utils.is_main_process():\n",
        "            with (Path(args.output_dir) / \"log.txt\").open(\"a\") as f:\n",
        "                f.write(json.dumps(log_stats) + \"\\n\")\n",
        "    total_time = time.time() - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "    print('Training time {}'.format(total_time_str))\n",
        "\n",
        "\n",
        "def train_one_epoch(student, teacher, teacher_without_ddp, dino_loss, data_loader,\n",
        "                    optimizer, lr_schedule, wd_schedule, momentum_schedule,epoch,\n",
        "                    fp16_scaler, args):\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = 'Epoch: [{}/{}]'.format(epoch, args.epochs)\n",
        "    for it, (images, labels) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n",
        "        # update weight decay and learning rate according to their schedule\n",
        "        it = len(data_loader) * epoch + it  # global training iteration\n",
        "        for i, param_group in enumerate(optimizer.param_groups):\n",
        "            param_group[\"lr\"] = lr_schedule[it]\n",
        "            if i == 0:  # only the first group is regularized\n",
        "                param_group[\"weight_decay\"] = wd_schedule[it]\n",
        "\n",
        "        # move images to gpu\n",
        "        images = [im.cuda(non_blocking=True) for im in images]\n",
        "        # teacher and student forward passes + compute dino loss\n",
        "\n",
        "        with torch.cuda.amp.autocast(fp16_scaler is not None):\n",
        "            teacher_output = teacher(images[:2])  # only the 2 global views pass through the teacher\n",
        "            dice=random.random()\n",
        "            if dice>0.6:\n",
        "              #############\n",
        "              # Get the number of tensors in the list\n",
        "              label_to_indices = {int(label): [] for label in torch.unique(labels)}\n",
        "              for i, label in enumerate(labels):\n",
        "                  label_to_indices[int(label)].append(i)\n",
        "              for i in label_to_indices.keys():\n",
        "                  label_to_indices[i]=random.sample(label_to_indices[i], len(label_to_indices[i])) \n",
        "              indeces = [label_to_indices[a.item()].pop()for a in labels]\n",
        "              result = [torch.empty_like(image) for image in images]\n",
        "              # images=[images[i] for i in indeces]\n",
        "              for i in range(len(images)):\n",
        "                for k, j in enumerate(indeces):\n",
        "                  result[i][k]=images[i][j]\n",
        "                # images[i]=[images[i][j] for j in indeces]\n",
        "              # print(len(images))\n",
        "              # print(len(shuffled_indices))\n",
        "\n",
        "              ###############\n",
        "\n",
        "            \n",
        "\n",
        "              student_output = student(result)\n",
        "            else:\n",
        "              student_output = student(images)\n",
        "            \n",
        "            \n",
        "       \n",
        "\n",
        "            loss = dino_loss(student_output, teacher_output, epoch)\n",
        "\n",
        "        if not math.isfinite(loss.item()):\n",
        "            print(\"Loss is {}, stopping training\".format(loss.item()), force=True)\n",
        "            sys.exit(1)\n",
        "\n",
        "        # student update\n",
        "        optimizer.zero_grad()\n",
        "        param_norms = None\n",
        "        if fp16_scaler is None:\n",
        "            loss.backward()\n",
        "            if args.clip_grad:\n",
        "                param_norms = utils.clip_gradients(student, args.clip_grad)\n",
        "            utils.cancel_gradients_last_layer(epoch, student,\n",
        "                                              args.freeze_last_layer)\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            fp16_scaler.scale(loss).backward()\n",
        "            if args.clip_grad:\n",
        "                fp16_scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place\n",
        "                param_norms = utils.clip_gradients(student, args.clip_grad)\n",
        "            utils.cancel_gradients_last_layer(epoch, student,\n",
        "                                              args.freeze_last_layer)\n",
        "            fp16_scaler.step(optimizer)\n",
        "            fp16_scaler.update()\n",
        "\n",
        "        # EMA update for the teacher\n",
        "        with torch.no_grad():\n",
        "            m = momentum_schedule[it]  # momentum parameter\n",
        "            for param_q, param_k in zip(student.module.parameters(), teacher_without_ddp.parameters()):\n",
        "                param_k.data.mul_(m).add_((1 - m) * param_q.detach().data)\n",
        "\n",
        "        # logging\n",
        "        torch.cuda.synchronize()\n",
        "        metric_logger.update(loss=loss.item())\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "        metric_logger.update(wd=optimizer.param_groups[0][\"weight_decay\"])\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_one_epoch_supervised(student, teacher, teacher_without_ddp, dino_loss, data_loader,data_loader2,\n",
        "                    optimizer, lr_schedule, wd_schedule, momentum_schedule,epoch,\n",
        "                    fp16_scaler, args):\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = 'Epoch: [{}/{}]'.format(epoch, args.epochs)\n",
        "    # for it, (images, _) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n",
        "    for it, (batch1, batch2) in enumerate(metric_logger.log_every(list(zip(data_loader, data_loader2)), 10, header)):\n",
        "\n",
        "        # update weight decay and learning rate according to their schedule\n",
        "        it = len(data_loader) * epoch + it  # global training iteration\n",
        "        for i, param_group in enumerate(optimizer.param_groups):\n",
        "            param_group[\"lr\"] = lr_schedule[it]\n",
        "            if i == 0:  # only the first group is regularized\n",
        "                param_group[\"weight_decay\"] = wd_schedule[it]\n",
        "\n",
        "        # move images to gpu\n",
        "        # images = [im.cuda(non_blocking=True) for im in images]\n",
        "        images = [im.cuda(non_blocking=True) for im in batch1[0]]\n",
        "        images2 = [im.cuda(non_blocking=True) for im in batch2[0]]\n",
        "\n",
        "        \n",
        "        # teacher and student forward passes + compute dino loss\n",
        "        with torch.cuda.amp.autocast(fp16_scaler is not None):\n",
        "            teacher_output = teacher(images[:2])  # only the 2 global views pass through the teacher\n",
        "            student_output = student(images2)\n",
        "            loss = dino_loss(student_output, teacher_output, epoch)\n",
        "\n",
        "        if not math.isfinite(loss.item()):\n",
        "            print(\"Loss is {}, stopping training\".format(loss.item()), force=True)\n",
        "            sys.exit(1)\n",
        "\n",
        "        # student update\n",
        "        optimizer.zero_grad()\n",
        "        param_norms = None\n",
        "        if fp16_scaler is None:\n",
        "            loss.backward()\n",
        "            if args.clip_grad:\n",
        "                param_norms = utils.clip_gradients(student, args.clip_grad)\n",
        "            utils.cancel_gradients_last_layer(epoch, student,\n",
        "                                              args.freeze_last_layer)\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            fp16_scaler.scale(loss).backward()\n",
        "            if args.clip_grad:\n",
        "                fp16_scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place\n",
        "                param_norms = utils.clip_gradients(student, args.clip_grad)\n",
        "            utils.cancel_gradients_last_layer(epoch, student,\n",
        "                                              args.freeze_last_layer)\n",
        "            fp16_scaler.step(optimizer)\n",
        "            fp16_scaler.update()\n",
        "\n",
        "        # EMA update for the teacher\n",
        "        with torch.no_grad():\n",
        "            m = momentum_schedule[it]  # momentum parameter\n",
        "            for param_q, param_k in zip(student.module.parameters(), teacher_without_ddp.parameters()):\n",
        "                param_k.data.mul_(m).add_((1 - m) * param_q.detach().data)\n",
        "\n",
        "        # logging\n",
        "        torch.cuda.synchronize()\n",
        "        metric_logger.update(loss=loss.item())\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "        metric_logger.update(wd=optimizer.param_groups[0][\"weight_decay\"])\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
        "\n",
        "\n",
        "\n",
        "class DINOLoss(nn.Module):\n",
        "    def __init__(self, out_dim, ncrops, warmup_teacher_temp, teacher_temp,\n",
        "                 warmup_teacher_temp_epochs, nepochs, student_temp=0.1,\n",
        "                 center_momentum=0.9):\n",
        "        super().__init__()\n",
        "        self.student_temp = student_temp\n",
        "        self.center_momentum = center_momentum\n",
        "        self.ncrops = ncrops\n",
        "        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n",
        "        # we apply a warm up for the teacher temperature because\n",
        "        # a too high temperature makes the training instable at the beginning\n",
        "        self.teacher_temp_schedule = np.concatenate((\n",
        "            np.linspace(warmup_teacher_temp,\n",
        "                        teacher_temp, warmup_teacher_temp_epochs),\n",
        "            np.ones(nepochs - warmup_teacher_temp_epochs) * teacher_temp\n",
        "        ))\n",
        "\n",
        "    def forward(self, student_output, teacher_output, epoch):\n",
        "        \"\"\"\n",
        "        Cross-entropy between softmax outputs of the teacher and student networks.\n",
        "        \"\"\"\n",
        "        student_out = student_output / self.student_temp\n",
        "        student_out = student_out.chunk(self.ncrops)\n",
        "\n",
        "        # teacher centering and sharpening\n",
        "        temp = self.teacher_temp_schedule[epoch]\n",
        "        teacher_out = F.softmax((teacher_output - self.center) / temp, dim=-1)\n",
        "        teacher_out = teacher_out.detach().chunk(2)\n",
        "\n",
        "        total_loss = 0\n",
        "        n_loss_terms = 0\n",
        "        for iq, q in enumerate(teacher_out):\n",
        "            for v in range(len(student_out)):\n",
        "                if v == iq:\n",
        "                    # we skip cases where student and teacher operate on the same view\n",
        "                    continue\n",
        "                loss = torch.sum(-q * F.log_softmax(student_out[v], dim=-1), dim=-1)\n",
        "                total_loss += loss.mean()\n",
        "                n_loss_terms += 1\n",
        "        total_loss /= n_loss_terms\n",
        "        self.update_center(teacher_output)\n",
        "        return total_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_center(self, teacher_output):\n",
        "        \"\"\"\n",
        "        Update center used for teacher output.\n",
        "        \"\"\"\n",
        "        batch_center = torch.sum(teacher_output, dim=0, keepdim=True)\n",
        "        dist.all_reduce(batch_center)\n",
        "        batch_center = batch_center / (len(teacher_output) * dist.get_world_size())\n",
        "\n",
        "        # ema update\n",
        "        self.center = self.center * self.center_momentum + batch_center * (1 - self.center_momentum)\n",
        "\n",
        "\n",
        "class DataAugmentationDINO(object):\n",
        "    def __init__(self, global_crops_scale, local_crops_scale, local_crops_number):\n",
        "        flip_and_color_jitter = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomApply(\n",
        "                [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)],\n",
        "                p=0.8\n",
        "            ),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "        ])\n",
        "        normalize = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ])\n",
        "\n",
        "        # first global crop\n",
        "        self.global_transfo1 = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=global_crops_scale, interpolation=Image.BICUBIC),\n",
        "            flip_and_color_jitter,\n",
        "            utils.GaussianBlur(1.0),\n",
        "            normalize,\n",
        "        ])\n",
        "        # second global crop\n",
        "        self.global_transfo2 = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=global_crops_scale, interpolation=Image.BICUBIC),\n",
        "            flip_and_color_jitter,\n",
        "            utils.GaussianBlur(0.1),\n",
        "            utils.Solarization(0.2),\n",
        "            normalize,\n",
        "        ])\n",
        "        # transformation for the local small crops\n",
        "        self.local_crops_number = local_crops_number\n",
        "        self.local_transfo = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(96, scale=local_crops_scale, interpolation=Image.BICUBIC),\n",
        "            flip_and_color_jitter,\n",
        "            utils.GaussianBlur(p=0.5),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "    def __call__(self, image):\n",
        "        crops = []\n",
        "        crops.append(self.global_transfo1(image))\n",
        "        crops.append(self.global_transfo2(image))\n",
        "        for _ in range(self.local_crops_number):\n",
        "            crops.append(self.local_transfo(image))\n",
        "        return crops\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser('DINO', parents=[get_args_parser()])\n",
        "    args = parser.parse_args(\"\")\n",
        "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    train_dino(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "files=os.listdir('/content/drive/MyDrive/MICCAI/dataset/CRC/train/s3/')"
      ],
      "metadata": {
        "id": "-agB9j_mQfPV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1W6ni2kQqqs",
        "outputId": "d1a625c9-ffb7-4cc9-b95d-69bd72282001"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1236"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JEJ50DJwQr1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}